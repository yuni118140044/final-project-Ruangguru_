# -*- coding: utf-8 -*-
"""final project Ruangguru

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LZYmaLfOZsYX0qqJDpnOTL9sEloDD9l3
"""

#

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.pylab import rcParams #Untuk visualisasi
from datetime import datetime #Untuk mengatasi tipe data tanggal

data = pd.read_csv('21-06.csv')
data1 = pd.read_csv('data date.csv')

data

data1

# a = pd.DataFrame(data)
# b= pd.DataFrame(data1)

# import pandas as pd
# pd.DataFrame.concat([a,b], axis=1)

data1

# data = data.assign(time = data1['create_at'])
# data

data.isna().sum()

data.shape

data.dtypes

data['created_at'] = pd.to_datetime(data['created_at'], infer_datetime_format=True)
data['sold_at'] = pd.to_datetime(data['sold_at'], infer_datetime_format=True)
# data['created_at'] = data['created_at'].dt.strftime('%m/%d/%Y')
data.dtypes

a = data.drop(['id','id-2','product_id','sold_at','brand','product_sku','product_department','name','product_name','product_brand','product_distribution_center_id','product_sku','sku','distribution_center_id'], axis =1)
a

a.isna().sum()

a.describe()



a.isnull()

a.nunique

a.isna().sum()

persentase_cost2 = a['cost-2'].isna().mean()*100
print('persentase data yang hiang pada column Cost 2 = {:.2f}%'.format(persentase_cost2))
persentase_pc = a['product_category'].isna().mean()*100
print('persentase data yang hiang pada column product category = {:.2f}%'.format(persentase_pc))
persentase_prp = a['product_retail_price'].isna().mean()*100
print('persentase data yang hiang pada column product retail category = {:.2f}%'.format(persentase_prp))

a['category'].unique()

plt.figure(figsize=(12,7))
plt.bar(a['category'], a['cost'], color='lightcoral')

plt.title('persebaran data category product', size=16)
plt.ylabel('cost', size=12)
plt.xticks(size=12)
plt.yticks(size=12)

plt.show()

a['department'].hist()

rata_price_produk = a['product_retail_price'].mean()
a['product_retail_price'] = a['product_retail_price'].fillna(rata_price_produk)
a['product_retail_price'].isna().sum()

rata_cost2 = a['cost-2'].mean()
a['cost-2'] = a['cost-2'].fillna(rata_cost2)
a['cost-2'].isna().sum()

rata_cost = a['retail_price'].mean()
a['retail_price'] = a['retail_price'].fillna(rata_cost)
a['retail_price'].isna().sum()

a.isna().sum()

a['product_category'].value_counts()

a['product_category'] = a['product_category'].fillna(method = 'bfill')

a['product_category'].value_counts()

a.isna().sum()
a.drop(['created_at'], axis =1)

a.duplicated()

corr = a.corr()

corr

plt.figure(figsize=(9,9))
sns.heatmap(a.corr(), cmap='coolwarm', linewidths=2, annot=True)
plt.show()

a.describe()

import scipy.stats as stats



sns.boxplot(a['cost'])

sns.histplot(a['cost'])

sns.regplot(x='cost',y='product_retail_price',data=a)

sns.regplot(x='cost',y='cost-2',data=a)

sns.scatterplot(x='cost',y='product_retail_price',data=a)

sns.regplot(x='cost-2',y='product_retail_price',data=a)

len(a)

ratio = a['retail_price'] - a['cost']
ratio
a['ratio'] = ratio

f= plt.figure(figsize=(12,4))

ax=f.add_subplot(121)
sns.distplot(a['ratio'],bins=50,color='r',ax=ax)
ax.set_title('Distribution data Product')

ax=f.add_subplot(122)
sns.distplot(np.log10(a['cost']),bins=40,color='b',ax=ax)
ax.set_title('Distribution of insurance charges in $log$ sacle')
ax.set_xscale('log');

a



b = a.drop(['category','department'], axis = 1)
a =b

a.drop(columns ='created_at')



from sklearn import preprocessing
lb = preprocessing.LabelEncoder()
a['product_category'] = lb.fit_transform(a['product_category'])
a['product_category'].unique()

a = a.drop(columns = 'created_at')

from sklearn import preprocessing
minmax = preprocessing.MinMaxScaler().fit_transform(a)
minmax

data3 = pd.DataFrame(minmax, index=a.index, columns=a.columns[::])
data3

from sklearn.cluster import KMeans

scr=[]
for i in range(1,20):
    score = KMeans(n_clusters=i).fit(data3).score(data3)
    print(score)
    scr.append(score)

scr

plt.plot(scr)

kmeans = KMeans(n_clusters =2)
kmeans.fit(data3)

kmeans.labels_

data3['Cluster'] = kmeans.labels_
data3

sns.pairplot(data3, hue='Cluster')

# Commented out IPython magic to ensure Python compatibility.
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs
from sklearn.metrics import silhouette_samples
import matplotlib.pyplot as plt
import matplotlib as mpl
from matplotlib.ticker import FixedLocator, FixedFormatter
from pylab import rcParams

# %matplotlib inline

data3

X = data3.iloc[:, :].values


rcParams['figure.figsize'] =16,5

a= plt.plot(data3['cost'], data3['product_retail_price'],
           linestyle=None, linewidth=0, marker='o', markersize='5', color='red')
a= plt.title('persebaran data pada rangking Universitas di Dunia Tahun 2020', fontsize='14')
a= plt.grid(which='major')
a= plt.xlabel('cost')
a= plt.ylabel('product_retail_price')
a= plt.show()

X

#metode clasical elbow
elbow = []

for i in range(1, 10):
    #masukkan algoritma kmeans
    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300,
                   n_init = 10, random_state = 42)
    kmeans.fit(X)
    
    elbow.append(kmeans.inertia_)

#plot metode elbow

a= plt.plot(range(1,10), elbow, linewidth = 4, color='black', marker='D', markersize=10)
a= plt.title('metode elbow')
a= plt.xlabel('number of Cluster', fontsize=12)
a= plt.ylabel('WCSS inertia', fontsize=12)
a= plt.xticks(fontsize='8', color='black')
a= plt.yticks(fontsize='8', color='black')
a= plt.grid(which ='both', color='black', axis='x', alpha=0.5)

number_of_clusters = 5

a= plt.axvline(x=number_of_clusters, linewidth =3, color='blue', linestyle='--')
a= plt.show()

#silhoouette score
from sklearn.metrics import silhouette_score
silhouette_score(X, kmeans.labels_)







from sklearn.model_selection import train_test_split

train, test = train_test_split(data3, test_size = 0.2, random_state= 42)

print("Banyak data yang akan di training = ",len(train))
print("Banyak data yang akan di Testing = ",len(test))

train.head()

test.head()

train2, val = train_test_split(train, test_size=0.2, random_state=42)

print("Banyak data yang akan di training = ",len(train2))
print("Banyak data yang akan di validasi = ",len(val))
print("Banyak data yang akan di Testing = ",len(test))

profit_cost = data3['cost-2'] - data3['cost']
profit_cost

a = data3



y = a['Cluster']

x= a.drop(columns ='Cluster')
x

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

print("Banyak data pada X Train = ",len(x_train))
print("Banyak data pada Y Train = ",len(y_train))
print("Banyak data pada X Test = ",len(x_test))
print("Banyak data pada Y Test = ",len(y_test))

from sklearn import metrics
from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()
# fit the model
gnb.fit(x_train, y_train)

#Melakukan prediksi terhadap data testing dan probabilitasnya
y_predict = gnb.predict(x_test)

# dtree = DecisionTreeClassifier()
# dtree = dtree.fit(x_train, y_train)
# y_predict = dtree.predict(x_test)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
confusion_matrix = confusion_matrix(y_test,y_predict)
print(confusion_matrix)

sns.heatmap(confusion_matrix,annot=True,cmap="Blues",fmt="d",cbar=False, annot_kws={"size":20})

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix
print("Accuracy:", (metrics.accuracy_score(y_test, y_predict))*100)
print("Precision:", (metrics.precision_score(y_test, y_predict))*100)
print("Recall:", (metrics.recall_score(y_test, y_predict))*100)
print("F1:", (metrics.f1_score(y_test, y_predict))*100)

from sklearn.tree import DecisionTreeClassifier

clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)


# fit the model
clf_gini.fit(x_train, y_train)

y_pred_gini = clf_gini.predict(x_test)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
confusion_matrix = confusion_matrix(y_test,y_pred_gini)
print(confusion_matrix)

sns.heatmap(confusion_matrix,annot=True,cmap="Blues",fmt="d",cbar=False, annot_kws={"size":20})

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix
print("Accuracy:", (metrics.accuracy_score(y_test, y_pred_gini))*100)
print("Precision:", (metrics.precision_score(y_test, y_pred_gini))*100)
print("Recall:", (metrics.recall_score(y_test, y_pred_gini))*100)
print("F1:", (metrics.f1_score(y_test, y_pred_gini))*100)

plt.figure(figsize=(12,8))

from sklearn import tree

tree.plot_tree(clf_gini.fit(x_train, y_train))

# import SVC classifier
from sklearn.svm import SVC



# instantiate classifier with default hyperparameters
svc=SVC() 


# fit classifier to training set
svc.fit(x_train,y_train)


# make predictions on test set
y_pred=svc.predict(x_test)


# compute and print accuracy score
print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix
print("Accuracy:", (metrics.accuracy_score(y_test, y_pred))*100)
print("Precision:", (metrics.precision_score(y_test, y_pred))*100)
print("Recall:", (metrics.recall_score(y_test, y_pred))*100)
print("F1:", (metrics.f1_score(y_test, y_pred))*100)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
confusion_matrix = confusion_matrix(y_test,y_pred)
print(confusion_matrix)

sns.heatmap(confusion_matrix,annot=True,cmap="Blues",fmt="d",cbar=False, annot_kws={"size":20})

from sklearn.neighbors import KNeighborsClassifier
from sklearn import neighbors

knn = KNeighborsClassifier(2)

knn.fit(x_train, y_train)

knn.score(x_test, y_test)

from sklearn.metrics import classification_report, confusion_matrix
#let us get the predictions using the classifier we had fit above
y_pred = knn.predict(x_test)
confusion_matrix(y_test,y_pred)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
confusion_matrix = confusion_matrix(y_test,y_pred)
print(confusion_matrix)

sns.heatmap(confusion_matrix,annot=True,cmap="Blues",fmt="d",cbar=False, annot_kws={"size":20})

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix
print("Accuracy:", (metrics.accuracy_score(y_test, y_pred))*100)
print("Precision:", (metrics.precision_score(y_test, y_pred))*100)
print("Recall:", (metrics.recall_score(y_test, y_pred))*100)
print("F1:", (metrics.f1_score(y_test, y_pred))*100)

# a

a

ratio = a['retail_price']-a['product_retail_price']
ratio

a['ratio'] = ratio

a



f= plt.figure(figsize=(12,4))

ax=f.add_subplot(121)
sns.distplot(a['ratio'],bins=50,color='r',ax=ax)
ax.set_title('Distribution data Product')

ax=f.add_subplot(122)
sns.distplot(np.log10(a['cost']),bins=40,color='b',ax=ax)
ax.set_title('Distribution of insurance charges in $log$ sacle')
ax.set_xscale('log');

29120-26786

































































